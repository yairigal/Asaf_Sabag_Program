Newsgroups altatheism 
Path cantaloupesrvcscmuedudasnewsharvardedunocnearnetuunetpipexuknetwarwicknottcskax 
From kaxcsnottacuk Kevin Anthoney 
Subject Re Consciousness part II  Kev Strikes Back 
MessageID 
Organization Nottingham University 
References 
Date Wed 21 Apr 93 163848 GMT 
Lines 102 
 
In article 
kempmpphoenixoulufi Petri Pihko writes 
 
>Kevin Anthoney kaxcsnottacuk wrote 
> 
> This post is probably either brilliant or insane Do let me know 
> which  
> 
>A brilliant example of using the introspective objection against  
>materialist theories of consciousness 
 
Diplomatic  
 
I realize Im fighting Occams razor in this argument so Ill try to 
explain why I feel a mind is necessary  
 
Firstly Im not impressed with the ability of algorithms Theyre 
great at solving problems once the method has been worked out but not 
at working out the method itself 
 
As a specific example I like to solve numerical crosswords not the 
simple dothesumsandinserttheanswers type the hard ones To do 
these with any efficiency you need to figure out a variety of tricks 
Now I know that you can program a computer to do these puzzles but 
in doing so you have to work out the tricks yourself and program 
them into the computer You can of course obfuscate the trick and 
write the program so that it is uncovered but as far as I can see 
the trick still has to be there in some form to be discovered Does 
this mean that all the ideas we will ever have are already 
preprogrammed into our brains This is somewhat unlikely given that 
our brains ultimately are encoded in 46 chromosomes worth of genetic 
material much of which isnt used 
 
One way around this is to bring the environment into the equation but 
again as far as I can see this still has an air of if you see 
object X then perform action Y and we dont seem to get anywhere 
The algorithm has to anticipate what it might see and what 
conclusions to draw from its experience 
 
The other problem with algorithms is their instability Not many 
algorithms survive if you take out a large portion of their code yet 
people survive strokes without going completely haywire there are 
sideeffects but patients still seem remarkably stable Also 
neurons in perfectly healthy people are dying at an alarming rate  
can an algorithm survive if I randomly corrupt various bits of its 
code 
 
The next problem is the sticky question of What is colour replace 
colour with the sensation of your choice Presumably the 
materialist viewpoint is that its the product of some kind of 
chemical reaction The usual products of such a reaction are energy + 
different chemicals Is colour a mixture of these If this is so a 
computer wont see colour because the chemistry is different Does an 
algorithm that sees colour have a selective advantage over an 
equivalent that doesnt It shouldnt because the outputs of each 
algorithm ought to be the same in equivalent circumstances So why do 
we 